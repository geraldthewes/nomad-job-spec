# LLM Configuration
LLM_PROVIDER=vllm
VLLM_BASE_URL=http://localhost:8000
VLLM_MODEL=Qwen/Qwen3-32B
LLM_TEMPERATURE=0.1
LLM_MAX_TOKENS=4096

# For OpenAI (if using openai provider)
# OPENAI_API_KEY=sk-...

# For Anthropic (if using anthropic provider)
# ANTHROPIC_API_KEY=sk-ant-...

# Nomad Configuration
NOMAD_ADDRESS=http://localhost:4646
# NOMAD_TOKEN=your-acl-token
NOMAD_NAMESPACE=default
NOMAD_REGION=global
NOMAD_DATACENTER=dc1

# Memory Layer (Mem0 + Qdrant)
QDRANT_HOST=localhost
QDRANT_PORT=6333
QDRANT_COLLECTION=nomad_agent
MEMORY_ENABLED=true

# Observability (LangFuse)
LANGFUSE_ENABLED=true
# LANGFUSE_PUBLIC_KEY=pk-...
# LANGFUSE_SECRET_KEY=sk-...
LANGFUSE_HOST=https://cloud.langfuse.com

# Agent Configuration
MAX_ITERATIONS=3
VERIFICATION_TIMEOUT=300
VERIFICATION_POLL_INTERVAL=10

# Resource Defaults
DEFAULT_CPU=500
DEFAULT_MEMORY=256

# Logging
LOG_LEVEL=INFO
