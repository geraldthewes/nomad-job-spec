# LLM Configuration
LLM_PROVIDER=vllm
VLLM_BASE_URL=http://localhost:8000/v1
VLLM_MODEL=Qwen/Qwen3-32B
LLM_TEMPERATURE=0.1
LLM_MAX_TOKENS=4096

# For OpenAI (if using openai provider)
# OPENAI_API_KEY=sk-...

# For Anthropic (if using anthropic provider)
# ANTHROPIC_API_KEY=sk-ant-...

# Nomad Configuration
NOMAD_ADDR=http://localhost:4646
# NOMAD_TOKEN=your-acl-token
NOMAD_NAMESPACE=default
NOMAD_REGION=global
NOMAD_DATACENTER=dc1

# Vault Configuration
VAULT_ADDR=http://localhost:8200
# VAULT_TOKEN=hvs.xxx  # Or set via `vault login`
# VAULT_NAMESPACE=     # Enterprise only

# Consul Configuration
CONSUL_HTTP_ADDR=http://localhost:8500
# CONSUL_HTTP_TOKEN=   # ACL token if required
CONSUL_CONVENTIONS_PATH=config/nomad-agent/conventions

# Fabio Configuration
FABIO_ADMIN_ADDR=http://localhost:9998

# Memory Layer (Mem0 + Qdrant)
QDRANT_HOST=localhost
QDRANT_PORT=6333
QDRANT_COLLECTION=nomad_agent
MEMORY_ENABLED=true

# Observability (LangFuse)
# Both LANGFUSE_PUBLIC_KEY and LANGFUSE_SECRET_KEY are required when enabled
# See: https://langfuse.com/docs/sdk/python/low-level-sdk
LANGFUSE_ENABLED=false
# LANGFUSE_PUBLIC_KEY=pk-lf-...
# LANGFUSE_SECRET_KEY=sk-lf-...
LANGFUSE_BASE_URL=https://cloud.langfuse.com
LANGFUSE_PROMPT_LABEL=development

# Agent Configuration
MAX_ITERATIONS=3
VERIFICATION_TIMEOUT=300
VERIFICATION_POLL_INTERVAL=10

# Resource Defaults
DEFAULT_CPU=500
DEFAULT_MEMORY=256

# Logging
LOG_LEVEL=INFO
